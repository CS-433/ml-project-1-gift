# Higgs Boson Challenge EPFL 2022 - Machine Learning (CS-433)
The repository is organized as follows:
 - useful documentation and references consulted during the project (DOCUMENTATION folder)
 - (down-) loading of the dataset and (up-) loading of the results (loading_dataset.py)
 - preliminary inspection of the dataset (INSPECTION folder) QUI DENTRO METTIAMO ANCHE I PLOT
 - cleaning of the dataset (cleaning_dataset.py)
 - manipulation techniques on the features of the dataset (feature_engineering.py)
 - regression (REGRESSION FOLDER utilities_linear_regression.py, utilities_logistic_regression.py and implementation.py)
 - 'main' code, including all the trials that led us to the final results (MAIN folder, finalrun.py)

# Team
This project is executed by the team GiFT with the following members:

Girolamo Vurro: @girolamovurro14
Francesca Venturi: @francescaventurigit
Tommaso Farnararo: @tommasofarnararo


# Project structure

## Presentation:
The challenge aims at studying and  implementing manipulation techinques on the dataset, in order to perform datamining and, eventually, reliable predictions.

## Documentation:
An effective and reliable data analysis is not able to leave a theoretical study of the problem out of consideration. A preliminary and, in our case, rough research on the Higgs Boson Challenge turns out to be fundamental. 

## Data Anlysis:
Data inspection (INSPECTION) necessarily predates the actual data analysis. All the features are analyzed to catch the distribution, the skewness, the correlation, the symmetry around the mean, in addition to the standard statistical quantities.

## Data Mining:
In addition to Logaritmic and Cosine tranforms, optimal polynomial expansion of the dataset is performed, too.

## Methods:
All the regression algorithms studied so far during the course are implemented: Gradient Descent, Stochastic Gradient Descent, Least Squares, Ridge Regression, Logistic Regression with Gradient Descent (penalized and non-penalized), Logistic Regression with Stochastic Gradient Descent (penalized and non-penalized), Logistic Regression with Newton Method.

## Envirnoment:
The project is developed and tested with python3.6. The required library for running the models and training is numpy. The library for visualization is matplotlib.

## Results:
Results to predict the test datasets are generated by running: python3 finalrun.py. And the final results are saved in: /data/finalsubmission.csv.
